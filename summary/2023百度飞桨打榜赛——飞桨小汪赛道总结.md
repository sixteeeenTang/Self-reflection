------

[TOC]

------

# 🎆“中国软件杯”大学生软件设计大赛——飞桨小汪赛道

# ✨首先说明本次比赛的信息

本次比赛的官网：[飞桨AI Studio - 人工智能学习与实训社区 (baidu.com)](https://aistudio.baidu.com/aistudio/competition/detail/771/0/task-definition)

## 本次比赛的介绍

> #### **大赛介绍**
>
> “中国软件杯”大学生软件设计大赛是一项面向中国在校学生的公益性赛事，是2021年全国普通高校大学生竞赛榜单内竞赛。大赛由国家工业和信息化部、教育部、江苏省人民政府共同主办，致力于正确引导我国在校学生积极参加软件科研活动，切实增强自我创新能力和实际动手能力，为我国软件和信息技术服务业培养出更多高端、优秀的人才。
>
> #### **赛道介绍**
>
> 电力系统安全对经济的发展起着无可替代的作用，任何一个环节发生事故，都可能带来连锁反应，会造成大面积的停电、人身伤亡、主设备损坏甚至造成全网崩溃的灾难性事故。变电站作为连接主干网和配电网的关键节点，如何保证它的正常运行直接关系整个电力系统的稳定安全。因此为了保证对变电站内主变、母线、开关等主要一次设备运行状态的实时监控，需要对变电站进行检查和维护。 传统变电站监控和巡视采取人工方式，通过人的感官对设备进行简单定性判断，会存在着很多不足。如劳动强度大、工作效率低、检测质量分散、手段单一等不足，人工检测的数据也无法准确、及时地接入管理信息系统。并且，随着无人值守模式的推广，巡视工作量越来越大，巡检到位率、及时性无法保证。
>
> 为了满足对供电质量日益提高的要求，更灵活实用的变电站四足机器人巡视系统得以应用。相比于传统的轮式机器人，四足机器人面对复杂地形更加有优势，而利用深度学习技术来进行复杂环境的感知，为电力系统巡视工作提供实时智能分析与决策支持，也逐渐成为了重要趋势。
>
> #### **比赛任务**
>
> **不限学历，高职和本科（及以上）在预选赛和区域赛中分开单独排名，总决赛在一起排名。**
>
> 参赛选手需利用深度学习和自动化控制实现以下两部分内容：
>
> 1. 在预选赛中，要求选手要求参赛者基于PaddlePaddle，利用企业提供的训练数据，实现一个能够对仪器仪表、火点、安全帽进行精确识别的深度学习模型;
> 2. 在区域赛和总决赛中，要求选手基于搭载PaddlePaddle框架的国产四足机器狗宇树Go1机器狗，在规定的地图上进行自动巡检、避障越障和指定任务的完成，根据各任务的完成质量和完成速度进行评分。
>
> #### **提交方式**
>
> 1. 预选赛中，选手需上传训练模型、预测代码及环境库（可选）的zip形式压缩包到AI Studio平台进行自动评测，得到分数。由官方提供自动评测所需的全部算力。
> 2. 区域赛和总决赛：晋级预选赛的团队，将免费获得一台宇树科技机器狗Go 1的借用，用于区域赛和总决赛，选手统一在线下地图进行竞技。区域赛需要同时提交技术报告word和技术演示视频，总决赛需要进行答辩。 （备赛所用地图和真实地图有差异）
>
> #### **参赛形式**
>
> 以组队报名形式参赛，每队成员不超过5名 (含5名，其中队长1名，指导教师1名，其他队员不超过3名)，指导教师应为学生所在学校的专职教师担任。
>
> 1. 登陆AI Studio，参赛团队使用已有百度账号或新注册百度账号报名，在线完善相关信息，并前往[“中国软件杯”](http://www.cnsoftbei.com/)大赛官网报名组队，最终报名信息以“中国软件杯”大赛官网为准。（队长在软件报名平台组队后，选此赛题，填写本人UID，UID可在AI Studio平台个人中心查看，最终AI Studio线上模型测评成绩将以此账号成绩为准）。每所院校报名队伍数量不限。
> 2. **组队报名方法**：队长确认报名参赛后，点击【复制链接邀请队员】，并将内容发送给 1名 即将加入队伍的队员，队员完善信息后可在“我的团队”中查看，此时表明队长已成功邀请 1名 队员加入战队。组队报名注意：邀请队员仅在 比赛报名截止前有效，邀请链接仅用于单名队员加入。自比赛报名截止前一天起（报名截止日期以“中国软件杯”大赛官网所发通知为准），队长不得转让队长身份、解散团队、移除队员，队员不得离开团队。
>
> #### **团队支持**
>
> 若团队所在高校，校赛人数低于300人，企业将在全国范围内，根据线上打榜赛成绩，向规定比例内的团队免费提供一台机器狗，供团队参加区域赛及国赛地图赛； 若团队所在高校，校赛人数多于300人，企业将为在校赛组织工作上表现突出的团队提供一台机器狗，若冠军在预选赛比例内，则该校共计两台。
>
> 注：校赛组织者请与赛事企业主办方联系，我们可提供该校校赛的成绩评测及导出工作。
>
> #### **任务要求**
>
> 线上赛指定深度学习框架：PaddlePaddle； 地图赛指定平台：搭载PaddlePaddle框架的宇树科技机器狗Go 1。

## 打榜赛要求

`本次打榜赛针对计算机视觉方向`

主要完成两个任务

1. 目标检测任务：对仪器仪表、火点、安全帽进行精确识别
2. 语义分割任务：对工业仪表的刻度和指针进行识别



以下是本次赛题的数据集地址以及内容：
[【智慧巡检】飞桨小汪复杂环境感知数据集 - 飞桨AI Studio (baidu.com)](https://aistudio.baidu.com/aistudio/datasetdetail/199384)

```apl
└── robot_dog_dataset # 数据集根目录
    ├── detection # 用于目标检测任务的数据集
    │   ├── annotations # 标签
    │   └── images # 图像
    └── segmentation # 用于语义分割任务的数据集
        ├── annotations # 标签
        └── images # 图像
```

本次比赛飞桨官方给出了baseline：
[【官方】2023年“中国软件杯”大学生软件设计大赛飞桨小汪赛道基线系统 - 飞桨AI Studio (baidu.com)](https://aistudio.baidu.com/aistudio/projectdetail/5718676)

# **✨然后是复盘打榜赛大致过程**

> 先说一下本次打榜赛的结果，获得了**总榜第26名（26/428）**，**武科大校赛第2名**的成绩![榜单排名](https://raw.githubusercontent.com/sixteeeenTang/img-storage/main/Quicker_20230730_232320.png)我认为作为我们的第一比赛实践，成果已经比较可观了。😊（不过提升空间也还很大）

我先总结一下我在这次打榜赛中学习的总过程。



## 🎐1.学习Linux命令

> [Linux命令大全(手册) – 真正好用的Linux命令在线查询网站 (linuxcool.com)](https://www.linuxcool.com/)

没有深入学习，只是看了一些很基础的Linux命令，比如文件管理命令（ls、cp……）、备份压缩命令（zip、unzip……），够在本次比赛中的ai studio环境中实现一些基础功能就浅尝辄止了。🖐在系统学习git时应该还需要更深入学习一些（也是时候把这个计划提上日程了）



## 🎐2.配置、处理数据集

🖐数据是十分十分十分重要的，所以要十分重视对数据集的处理！

> [COCO数据集的标注格式 - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/29393415)
>
> [【目标检测】从数据的角度深入解析比赛数据集的处理方法 - 飞桨AI Studio (baidu.com)](https://aistudio.baidu.com/aistudio/projectdetail/4116437)
>
> [(22条消息) LabelImg安装教程（已亲测）_喜欢大海的CC的博客-CSDN博客](https://blog.csdn.net/weixin_45145550/article/details/122528782?utm_medium=distribute.pc_relevant.none-task-blog-2~default~baidujs_baidulandingword~default-0-122528782-blog-125883343.235^v27^pc_relevant_recovery_v2&spm=1001.2101.3001.4242.1&utm_relevant_index=3)
>
> [(22条消息) 手把手实战教学！语义分割从0到1：一、数据集制作_segmentation npy_叶舟的博客-CSDN博客](https://blog.csdn.net/oYeZhou/article/details/115319298)
>
> [ctrl c+v妙用-利用复制粘贴技术增强数据集 - 掘金 (juejin.cn)](https://juejin.cn/post/6992174852891213861)

本次比赛涉及到两个任务的数据集，目标检测的数据集格式用的是`COCO`数据集格式（图像和标注文件信息存放在`json`文件中），语义分割的数据集格式用的是`VOC`数据集格式（对应每张图片都有一个`png`格式的`mask`图片）。

### ==1.目标检测数据集分析==

在本次比赛初期时，我就对目标检测的数据集进行了分析。统计了图像的尺寸分布、检测框高宽比分布、图片尺寸分析和标注框数量分析、检测框中心分布、训练集中各类标签数量。（在这里我把`json`格式换成了`xml`格式）



#### 图像尺寸分析

```python
# 图像尺寸分布
import os
from unicodedata import name
import xml.etree.ElementTree as ET
import glob

def Image_size(indir):
    # 提取xml文件列表
    os.chdir(indir)
    annotations = os.listdir('.')
    annotations = glob.glob(str(annotations) + '*.xml')
    width_heights = []

    for i, file in enumerate(annotations): # 遍历xml文件
        # actual parsing
        in_file = open(file, encoding = 'utf-8')
        tree = ET.parse(in_file)
        root = tree.getroot()
        width = int(root.find('size').find('width').text)
        height = int(root.find('size').find('height').text)
        if [width, height] not in width_heights: width_heights.append([width, height])
    print("数据集中，有{}种不同的尺寸，分别是：".format(len(width_heights)))
    for item in width_heights:
        print(item)

indir='/home/aistudio/work/data_voc/detection/train_annotations'   # xml文件所在的目录
Image_size(indir)
```

<details>
<summary>统计的图像尺寸内容较多，慎点！</summary>
<pre><code>
  数据集中，有865种不同的尺寸，分别是：
    [416, 415]
    [416, 416]
    [489, 302]
    [1024, 691]
    [480, 320]
    [1000, 932]
    [183, 275]
    [299, 169]
    [499, 339]
    [1920, 1080]
    [680, 453]
    [415, 416]
    [1217, 663]
    [250, 250]
    [500, 667]
    [1023, 683]
    [640, 640]
    [800, 450]
    [400, 300]
    [640, 317]
    [615, 462]
    [259, 194]
    [400, 299]
    [901, 548]
    [521, 300]
    [291, 173]
    [3552, 2368]
    [202, 250]
    [440, 293]
    [275, 183]
    [503, 300]
    [480, 360]
    [460, 259]
    [900, 600]
    [409, 269]
    [600, 405]
    [620, 407]
    [500, 372]
    [366, 550]
    [450, 290]
    [450, 334]
    [300, 202]
    [350, 215]
    [720, 480]
    [500, 310]
    [753, 342]
    [852, 480]
    [550, 263]
    [500, 375]
    [800, 531]
    [499, 304]
    [640, 426]
    [194, 259]
    [786, 519]
    [299, 168]
    [1024, 768]
    [960, 540]
    [580, 386]
    [449, 305]
    [383, 260]
    [300, 168]
    [1024, 682]
    [530, 788]
    [320, 240]
    [296, 170]
    [415, 415]
    [1365, 1024]
    [900, 601]
    [267, 189]
    [899, 598]
    [255, 198]
    [640, 480]
    [274, 184]
    [600, 400]
    [1024, 730]
    [400, 261]
    [948, 606]
    [1024, 695]
    [563, 300]
    [500, 332]
    [234, 310]
    [448, 598]
    [720, 720]
    [419, 254]
    [450, 309]
    [550, 343]
    [334, 248]
    [900, 598]
    [634, 422]
    [690, 1227]
    [634, 571]
    [450, 272]
    [399, 266]
    [800, 533]
    [201, 250]
    [500, 400]
    [550, 367]
    [263, 191]
    [300, 450]
    [1080, 1149]
    [487, 312]
    [850, 478]
    [720, 471]
    [550, 406]
    [500, 308]
    [494, 328]
    [516, 349]
    [524, 427]
    [1440, 1080]
    [450, 281]
    [840, 479]
    [900, 562]
    [400, 266]
    [950, 712]
    [225, 224]
    [499, 333]
    [262, 192]
    [964, 534]
    [600, 399]
    [750, 491]
    [440, 330]
    [658, 439]
    [634, 420]
    [450, 303]
    [1024, 683]
    [634, 438]
    [640, 425]
    [500, 313]
    [484, 600]
    [600, 450]
    [344, 458]
    [850, 519]
    [490, 336]
    [730, 496]
    [640, 400]
    [1050, 788]
    [500, 335]
    [300, 214]
    [1118, 737]
    [634, 391]
    [850, 550]
    [271, 186]
    [1055, 695]
    [300, 193]
    [550, 734]
    [310, 202]
    [293, 220]
    [540, 367]
    [810, 540]
    [607, 270]
    [1080, 810]
    [640, 427]
    [1000, 666]
    [350, 262]
    [870, 576]
    [800, 534]
    [600, 379]
    [1024, 680]
    [500, 334]
    [638, 450]
    [400, 277]
    [606, 670]
    [231, 218]
    [500, 457]
    [950, 619]
    [600, 398]
    [370, 204]
    [640, 360]
    [595, 335]
    [530, 341]
    [292, 173]
    [409, 510]
    [446, 435]
    [500, 368]
    [500, 333]
    [696, 1024]
    [1024, 869]
    [278, 181]
    [530, 530]
    [340, 226]
    [400, 256]
    [178, 181]
    [168, 300]
    [800, 597]
    [1080, 720]
    [360, 260]
    [900, 642]
    [640, 440]
    [800, 478]
    [253, 199]
    [471, 318]
    [400, 331]
    [683, 1024]
    [496, 280]
    [1280, 720]
    [544, 412]
    [550, 293]
    [400, 533]
    [450, 300]
    [1183, 622]
    [300, 200]
    [258, 196]
    [530, 351]
    [540, 335]
    [600, 665]
    [640, 967]
    [1024, 681]
    [294, 195]
    [800, 530]
    [960, 320]
    [550, 365]
    [350, 415]
    [510, 305]
    [500, 342]
    [410, 300]
    [450, 298]
    [640, 478]
    [227, 222]
    [450, 337]
    [281, 180]
    [800, 600]
    [600, 457]
    [266, 190]
    [640, 449]
    [325, 217]
    [549, 313]
    [292, 220]
    [557, 313]
    [410, 273]
    [400, 298]
    [960, 640]
    [800, 365]
    [231, 178]
    [960, 720]
    [541, 324]
    [467, 265]
    [550, 362]
    [1294, 779]
    [434, 480]
    [600, 337]
    [281, 179]
    [285, 177]
    [600, 375]
    [1024, 733]
    [800, 535]
    [773, 541]
    [397, 220]
    [524, 300]
    [300, 240]
    [288, 175]
    [1000, 563]
    [480, 359]
    [750, 486]
    [594, 807]
    [800, 523]
    [899, 674]
    [600, 338]
    [800, 532]
    [1024, 802]
    [300, 300]
    [851, 514]
    [237, 212]
    [2000, 1361]
    [384, 256]
    [276, 183]
    [590, 350]
    [337, 268]
    [300, 224]
    [700, 393]
    [960, 960]
    [584, 387]
    [585, 574]
    [590, 434]
    [720, 868]
    [940, 626]
    [380, 253]
    [500, 367]
    [800, 497]
    [600, 800]
    [497, 246]
    [930, 558]
    [400, 225]
    [264, 191]
    [360, 288]
    [490, 256]
    [604, 378]
    [500, 297]
    [600, 658]
    [720, 400]
    [640, 446]
    [770, 498]
    [283, 178]
    [540, 303]
    [280, 180]
    [1024, 628]
    [980, 653]
    [500, 300]
    [284, 177]
    [330, 219]
    [499, 326]
    [680, 1024]
    [900, 675]
    [400, 235]
    [780, 1040]
    [500, 343]
    [640, 330]
    [552, 300]
    [2500, 1667]
    [3536, 2662]
    [800, 514]
    [255, 197]
    [550, 417]
    [400, 345]
    [540, 339]
    [594, 708]
    [585, 561]
    [600, 415]
    [251, 201]
    [372, 502]
    [500, 331]
    [260, 194]
    [500, 317]
    [500, 321]
    [640, 537]
    [447, 299]
    [690, 518]
    [600, 321]
    [940, 634]
    [850, 613]
    [529, 300]
    [545, 241]
    [550, 366]
    [1080, 608]
    [400, 265]
    [550, 344]
    [450, 305]
    [700, 525]
    [548, 281]
    [290, 174]
    [697, 464]
    [450, 254]
    [1920, 1379]
    [690, 389]
    [640, 882]
    [640, 327]
    [1024, 395]
    [1024, 553]
    [178, 284]
    [500, 500]
    [500, 345]
    [500, 376]
    [483, 702]
    [272, 185]
    [225, 225]
    [500, 380]
    [2048, 1536]
    [700, 456]
    [840, 560]
    [500, 364]
    [435, 580]
    [349, 540]
    [369, 461]
    [540, 359]
    [499, 349]
    [500, 328]
    [546, 431]
    [541, 361]
    [1024, 575]
    [293, 172]
    [401, 226]
    [580, 330]
    [500, 679]
    [640, 428]
    [512, 702]
    [640, 366]
    [445, 561]
    [327, 154]
    [450, 323]
    [669, 1000]
    [530, 547]
    [640, 456]
    [512, 384]
    [800, 546]
    [410, 274]
    [550, 394]
    [901, 583]
    [799, 559]
    [722, 406]
    [448, 297]
    [600, 900]
    [647, 431]
    [950, 699]
    [950, 631]
    [404, 550]
    [470, 360]
    [600, 470]
    [930, 604]
    [500, 281]
    [588, 333]
    [470, 311]
    [450, 315]
    [680, 504]
    [550, 364]
    [550, 735]
    [309, 163]
    [500, 323]
    [266, 189]
    [320, 200]
    [640, 421]
    [550, 354]
    [900, 596]
    [400, 270]
    [1240, 698]
    [970, 647]
    [640, 429]
    [640, 381]
    [450, 600]
    [600, 433]
    [360, 480]
    [190, 110]
    [500, 659]
    [192, 263]
    [343, 220]
    [400, 222]
    [492, 267]
    [523, 504]
    [478, 299]
    [400, 302]
    [468, 336]
    [532, 300]
    [631, 614]
    [500, 371]
    [378, 500]
    [900, 530]
    [450, 244]
    [337, 292]
    [488, 332]
    [694, 1000]
    [502, 300]
    [1032, 774]
    [217, 232]
    [690, 460]
    [600, 334]
    [1280, 960]
    [1174, 661]
    [228, 222]
    [550, 983]
    [940, 627]
    [410, 204]
    [703, 425]
    [501, 302]
    [700, 522]
    [480, 271]
    [540, 405]
    [853, 480]
    [500, 418]
    [1200, 729]
    [700, 469]
    [540, 340]
    [500, 398]
    [828, 621]
    [231, 251]
    [450, 299]
    [498, 309]
    [548, 1024]
    [300, 239]
    [660, 372]
    [540, 360]
    [270, 187]
    [640, 405]
    [574, 429]
    [600, 402]
    [150, 120]
    [547, 310]
    [1142, 784]
    [1600, 1060]
    [546, 304]
    [800, 460]
    [273, 185]
    [534, 293]
    [549, 361]
    [1000, 634]
    [300, 205]
    [310, 205]
    [600, 343]
    [550, 352]
    [259, 195]
    [641, 325]
    [1540, 1024]
    [850, 621]
    [500, 889]
    [361, 239]
    [550, 380]
    [768, 1024]
    [500, 276]
    [600, 393]
    [634, 336]
    [950, 623]
    [1024, 574]
    [720, 502]
    [640, 233]
    [1440, 440]
    [590, 400]
    [205, 246]
    [1000, 750]
    [500, 752]
    [672, 444]
    [467, 296]
    [500, 365]
    [899, 600]
    [600, 369]
    [248, 203]
    [905, 568]
    [277, 182]
    [310, 163]
    [950, 633]
    [620, 818]
    [4085, 2969]
    [275, 184]
    [640, 362]
    [400, 288]
    [638, 426]
    [491, 869]
    [624, 349]
    [1024, 736]
    [640, 379]
    [400, 538]
    [500, 362]
    [919, 611]
    [302, 167]
    [640, 422]
    [764, 428]
    [450, 301]
    [882, 598]
    [195, 258]
    [304, 166]
    [314, 228]
    [652, 1024]
    [640, 857]
    [433, 580]
    [1200, 800]
    [1024, 679]
    [562, 750]
    [500, 350]
    [600, 893]
    [1080, 1284]
    [282, 179]
    [500, 320]
    [720, 576]
    [500, 347]
    [494, 330]
    [1245, 984]
    [540, 375]
    [539, 750]
    [530, 349]
    [500, 503]
    [993, 667]
    [300, 225]
    [720, 565]
    [1080, 600]
    [480, 314]
    [432, 322]
    [940, 625]
    [670, 463]
    [4032, 3024]
    [363, 600]
    [333, 500]
    [490, 332]
    [200, 253]
    [500, 392]
    [640, 384]
    [430, 564]
    [610, 434]
    [525, 353]
    [500, 270]
    [1280, 850]
    [460, 307]
    [263, 192]
    [799, 529]
    [1136, 518]
    [680, 373]
    [450, 306]
    [301, 167]
    [400, 257]
    [289, 175]
    [701, 468]
    [634, 475]
    [297, 170]
    [400, 251]
    [454, 302]
    [254, 198]
    [800, 451]
    [540, 467]
    [1080, 653]
    [177, 285]
    [192, 262]
    [1400, 909]
    [523, 308]
    [499, 334]
    [640, 442]
    [646, 484]
    [1024, 725]
    [521, 322]
    [400, 301]
    [640, 408]
    [241, 209]
    [640, 447]
    [1024, 685]
    [300, 401]
    [1036, 774]
    [336, 150]
    [1247, 808]
    [930, 633]
    [550, 397]
    [399, 247]
    [450, 297]
    [620, 350]
    [500, 286]
    [380, 326]
    [397, 241]
    [912, 600]
    [630, 290]
    [255, 350]
    [400, 273]
    [720, 479]
    [513, 342]
    [900, 488]
    [640, 382]
    [479, 319]
    [240, 135]
    [367, 137]
    [500, 358]
    [337, 270]
    [420, 529]
    [933, 430]
    [1061, 732]
    [500, 301]
    [500, 395]
    [1080, 1436]
    [540, 362]
    [540, 387]
    [300, 209]
    [400, 324]
    [600, 336]
    [856, 646]
    [500, 311]
    [400, 267]
    [500, 672]
    [610, 613]
    [276, 182]
    [850, 592]
    [577, 628]
    [500, 391]
    [650, 487]
    [500, 306]
    [470, 250]
    [499, 352]
    [1040, 753]
    [662, 506]
    [598, 405]
    [900, 506]
    [337, 600]
    [533, 300]
    [720, 960]
    [798, 530]
    [658, 900]
    [640, 482]
    [245, 206]
    [308, 164]
    [262, 193]
    [690, 390]
    [930, 618]
    [240, 180]
    [640, 424]
    [358, 225]
    [3528, 2280]
    [120, 80]
    [195, 259]
    [374, 446]
    [940, 588]
    [550, 479]
    [450, 295]
    [1920, 1152]
    [295, 171]
    [252, 200]
    [340, 225]
    [684, 632]
    [688, 454]
    [400, 274]
    [640, 989]
    [671, 1024]
    [305, 165]
    [1920, 1280]
    [580, 326]
    [630, 442]
    [950, 634]
    [1600, 1200]
    [450, 550]
    [500, 341]
    [600, 752]
    [690, 461]
    [320, 158]
    [400, 498]
    [500, 401]
    [400, 243]
    [530, 353]
    [850, 634]
    [798, 600]
    [913, 611]
    [640, 356]
    [850, 567]
    [230, 194]
    [316, 159]
    [249, 202]
    [636, 383]
    [600, 397]
    [710, 310]
    [500, 279]
    [183, 276]
    [600, 360]
    [342, 147]
    [1200, 1200]
    [600, 392]
    [400, 289]
    [400, 280]
    [300, 196]
    [847, 666]
    [406, 268]
    [400, 250]
    [1080, 715]
    [760, 530]
    [638, 638]
    [434, 640]
    [640, 457]
    [449, 355]
    [690, 1376]
    [407, 223]
    [1000, 535]
    [408, 800]
    [535, 357]
    [840, 527]
    [600, 420]
    [550, 733]
    [553, 275]
    [1024, 893]
    [600, 306]
    [644, 487]
    [1000, 619]
    [550, 405]
    [410, 264]
    [500, 655]
    [700, 448]
    [888, 577]
    [500, 330]
    [500, 477]
    [450, 675]
    [480, 336]
    [587, 338]
    [640, 410]
    [336, 222]
    [550, 409]
    [640, 800]
    [820, 1108]
    [841, 1024]
    [624, 680]
    [215, 234]
    [450, 360]
    [300, 194]
    [700, 315]
    [2048, 1242]
    [400, 287]
    [600, 300]
    [320, 450]
    [310, 519]
    [480, 720]
    [512, 288]
    [527, 300]
    [671, 442]
    [980, 551]
    [220, 286]
    [640, 267]
    [750, 1000]
    [1024, 528]
    [550, 412]
    [800, 529]
    [1000, 562]
    [1000, 631]
    [600, 340]
    [410, 306]
    [477, 720]
    [156, 235]
    [3872, 2592]
    [520, 346]
    [1176, 704]
    [641, 481]
    [500, 666]
    [307, 164]
    [550, 413]
    [534, 401]
    [327, 220]
    [477, 649]
    [1367, 910]
    [243, 208]
    [290, 173]
    [650, 433]
    [456, 261]
    [799, 531]
    [330, 220]
    [544, 582]
    [384, 217]
    [845, 562]
    [1070, 755]
    [720, 444]
    [540, 345]
    [500, 586]
    [793, 534]
    [700, 467]
    [600, 767]
    [750, 434]
    [780, 438]
    [694, 465]
    [800, 456]
    [530, 298]
    [700, 430]
    [633, 447]
    [720, 421]
    [440, 495]
    [800, 487]
    [1267, 713]
    [400, 239]
    [337, 470]
    [300, 227]
    [592, 457]
    [550, 440]
    [649, 401]
    [279, 181]
    [212, 238]
    [451, 712]
    [530, 797]
    [540, 358]
    [500, 378]
    [550, 309]
    [599, 571]
    [554, 417]
    [286, 486]
    [900, 649]
    [600, 417]
    [681, 1024]
    [541, 597]
    [400, 234]
    [500, 366]
    [640, 372]
    [240, 160]
    [650, 456]
    [670, 446]
    [500, 747]
    [500, 553]
    [676, 429]
    [1047, 600]
    [690, 730]
    [438, 289]
    [940, 633]
    [2048, 1336]
    [500, 336]
    [709, 473]
  </code></pre>
</details>



#### 检测框高宽比分析

```python
# 检测框高宽比分析
import os
import matplotlib.pyplot as plt
from unicodedata import name
import xml.etree.ElementTree as ET
import glob

def ratio(indir):
    # 提取xml文件列表
    os.chdir(indir)
    annotations = os.listdir('.')
    annotations = glob.glob(str(annotations) + '*.xml')
    # count_0, count_1, count_2, count_3 = 0, 0, 0, 0 # 举反例，不要这么写
    count = [0 for i in range(20)]

    for i, file in enumerate(annotations): # 遍历xml文件
        # actual parsing
        in_file = open(file, encoding = 'utf-8')
        tree = ET.parse(in_file)
        root = tree.getroot()

        # 遍历文件的所有检测框
        for obj in root.iter('object'):
            xmin = obj.find('bndbox').find('xmin').text
            ymin = obj.find('bndbox').find('ymin').text
            xmax = obj.find('bndbox').find('xmax').text
            ymax = obj.find('bndbox').find('ymax').text
            Aspect_ratio = (int(ymax)-int(ymin)) / (int(xmax)-int(xmin))
            if int(Aspect_ratio/0.25) < 19:
                count[int(Aspect_ratio/0.25)] += 1
            else:
                count[-1] += 1
    sign = [0.25*i for i in range(20)]
    plt.bar(x=sign, height=count)
    print(count)

indir='/home/aistudio/work/data_voc/detection/train_annotations'   # xml文件所在的目录
ratio(indir)
```



#### 图片尺寸分析和标注框数量分析

```python
import cv2
import json, os
from pycocotools.coco import COCO
from numpy import *
# json_path = '/home/aistudio/work/robot_dog_dataset/detection/annotations/val.json'
json_path = '/home/aistudio/work/robot_dog_dataset/detection/annotations/train.json'
area_list = []
width_list = []
height_list = []
GTlength_list = []
# 构建coco对象
coco = COCO(json_path)
# 获取所有的图像ID(list)
list_imgIds = coco.getImgIds() 
# 获取所有的类别ID(list)(本次比赛共5类：1~5)
catIds = coco.getCatIds()
# 获取所有的图像ID,用于数据增强
list_imgIds = coco.getImgIds() 
for imgId in list_imgIds:
    # 从list_imgIds中依次取得一个图像元素
    main_img = coco.loadImgs(imgId)[0]
    # 获取该图片中含有的所有标注信息的ID
    annIds = coco.getAnnIds(imgIds=main_img['id'], catIds=catIds, iscrowd=None)
    # 获取该图片中的标注信息
    img_anns = coco.loadAnns(annIds)
    # print(img_anns)
    GTlength_list.append(len(img_anns))
    # 遍历该图片中的所有标注信息
    for i in range(len(img_anns)):
        # 读取边框的坐标信息
        # x, y, w, h = img_anns[i]['bbox']
        area = img_anns[i]['area']  
        width_list.append(img_anns[i]['bbox'][2])
        height_list.append(img_anns[i]['bbox'][3])
        area_list.append(area)
        if img_anns[i]['bbox'][3] == 0:
            print('出现height为0的图片id为：',img_anns[i]['image_id'])
area_list.sort()
print('area的最小值为：',min(area_list))
print(area_list[0:5])
print('width最小值',min(width_list))
print('height最小值',min(height_list))
print('一张图片最多含有的框个数：',max(GTlength_list))
print('一张图片最少含有的框个数：',min(GTlength_list))
print('一张图片含有的框平均个数：',mean(GTlength_list))
```

```
area的最小值为： 5.0
[5.0, 20.0, 20.0, 20.0, 24.0]
width最小值 4.0
height最小值 1.0
一张图片最多含有的框个数： 68
一张图片最少含有的框个数： 1
一张图片含有的框平均个数： 4.050781936390792
```



#### 检测框中心分布

```python
import os
from unicodedata import name
import xml.etree.ElementTree as ET
import glob

def distribution(indir):
    # 提取xml文件列表
    os.chdir(indir)
    annotations = os.listdir('.')
    annotations = glob.glob(str(annotations) + '*.xml')
    data_x, data_y = [], []

    for i, file in enumerate(annotations): # 遍历xml文件
        # actual parsing
        in_file = open(file, encoding = 'utf-8')
        tree = ET.parse(in_file)
        root = tree.getroot()
        width = int(root.find('size').find('width').text)
        height = int(root.find('size').find('height').text)

        # 遍历文件的所有检测框
        for obj in root.iter('object'):
            xmin = int(obj.find('bndbox').find('xmin').text)
            ymin = int(obj.find('bndbox').find('ymin').text)
            xmax = int(obj.find('bndbox').find('xmax').text)
            ymax = int(obj.find('bndbox').find('ymax').text)
            x = (xmin + (xmax-xmin)) / width
            y = (ymin + (ymax-ymin)) / height
            data_x.append(x)
            data_y.append(y)
            
    plt.scatter(data_x, data_y, s=1, alpha=0.1)

indir='/home/aistudio/work/data_voc/detection/train_annotations'   # xml文件所在的目录
distribution(indir)
```



#### 各类标签数量

```python
# 对voc数据集格式的数据分析
import os
from unicodedata import name
import xml.etree.ElementTree as ET
import glob

def count_num(indir):
    # 提取xml文件列表
    os.chdir(indir)
    annotations = os.listdir('.')
    annotations = glob.glob(str(annotations) + '*.xml')

    dict = {} # 新建字典，用于存放各类标签名及其对应的数目
    for i, file in enumerate(annotations): # 遍历xml文件
       
        # actual parsing
        in_file = open(file, encoding = 'utf-8')
        tree = ET.parse(in_file)
        root = tree.getroot()

        # 遍历文件的所有标签
        for obj in root.iter('object'):
            name = obj.find('name').text
            if(name in dict.keys()): dict[name] += 1 # 如果标签不是第一次出现，则+1
            else: dict[name] = 1 # 如果标签是第一次出现，则将该标签名对应的value初始化为1

    # 打印结果
    print("各类标签的数量分别为：")
    for key in dict.keys(): 
        print(key + ': ' + str(dict[key]))            

indir='/home/aistudio/work/data_voc/detection/train_annotations'   # xml文件所在的目录
count_num(indir) # 调用函数统计各类标签数目
```

最明显的是发现`helmet`类的数量明显多于其他四类的总和，样本数量十分不均衡。

```
训练集中各类标签的数量：
fire: 2683
head: 4487
helmet: 15141
person: 676
meter: 66
```

```
验证集中各类标签的数量:
fire: 612
head: 1298
helmet: 3825
person: 75
meter: 10
```



### ==2.目标检测数据集处理==

在线数据增强的方案：

```python
TrainReader:
  sample_transforms:
    - Decode: {}  # 从图像文件或内存buffer中加载图像,格式为RGB格式
    - RandomDistort: {}   # 随机扰动图片亮度、对比度、饱和度和色相
    - RandomExpand: {fill_value: [123.675, 116.28, 103.53]} # 将原始图片放入用像素均值填充的扩张图中，对此图进行裁剪、缩放和翻转
    - RandomCrop: {}  # 原理同CropImage，以随机比例与IoU阈值进行处理
    - RandomFlip: {}  # 随机水平翻转图像
    # - Mixup: {alpha: 1.5, beta: 1.5}  # Mixup数据增强，按比例叠加两张图像
  batch_transforms:
    - BatchRandomResize: {target_size: [320, 352, 384, 416, 448, 480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800, 832, 864, 896, 928, 960], random_size: True, random_interp: True, keep_ratio: False}
    - NormalizeImage: {mean: [0., 0., 0.], std: [1., 1., 1.], norm_type: none}
    - Permute: {}
    - PadGT: {}
  batch_size: 8
  shuffle: true
  drop_last: true
  use_shared_memory: true
  collate_batch: true
  # mixup_epoch使用mixup的轮数，即在epoch < mixup_epoch时一直使用mixup。默认值为-1，表示不使用Mixup
  # mixup_epoch: 100
```



我发现`person`类的标注并不准确，如下图这两张图片中，第一张标注了`person`，而第二张中却没有标注`person`

![标注了person](https://raw.githubusercontent.com/sixteeeenTang/img-storage/main/Quicker_20230730_224453.png)![没有标注person](https://raw.githubusercontent.com/sixteeeenTang/img-storage/main/Quicker_20230730_224551.png)

于是我灵机一动，难不成这是这次比赛的提升点？抱着这个想法我就开始了行动。
我在本地用`yolov7`对训练集和验证集中的`person`进行了标注，然后把标注信息融合到了官方数据集中，并重新划分了训练集和验证集，这下`person`够多了，暴增到18340个。训练了60轮左右，发现mAp达到了惊人的0.87，这太夸张了（官方原始baseline很难跑过0.55）。但是在我激动地提交之后发现评分低得惊人，这让我大失所望，于是便放弃了继续这个方案的打算，任这个`person`类就按原样来了。

> 🖐这个方向上我花了不少时间来写脚本，但是结果却很差，当时真的是狠狠地打击到我了。😣

随后我就换了一个方向，我用离线数据增强（copy-paste）对`fire`类进行了增强，不过效果也不好，在验证集上的表现基本没有提升。于是便放弃了这个方向

> 🖐这里犯了一个错误，验证集只能作为一个参考，不能把验证集的作用和测试集等同了！所以即便在验证集上表现可能一般，也不要放弃提交，提交上去在测试集上的表现效果可能会不错。其实我在本次的目标检测任务中一直在犯这个错误！我对这个错误一直有比较模糊的认识，直到打榜赛结束我才能很清晰地意识到这样是错误的！

再之后便是一段时间没有对目标检测数据集进行处理，开始摆烂。后来受到龚思宇学长的建议，把`person`类直接在训练集和验证集中删掉，再训练。于是便训练了60轮左右，发现在验证集上的mAp虽然变高了，但是还是存在对`fire`类检测精度不高的问题；
然后又受到龚思宇学长的建议，考虑到标有`fire`类的图像的尺寸不均匀，而且预测框的大小分布也不均匀，就在原本`baseline`的基础上增加了图像的输入尺寸（这种情况下`batchsize`要调小一些，不然会爆显存），提交上去发现相较于我之前的尝试有一些提升，但不多，依旧是不如`baseline`里的`submission`，这很让人难过😣

> 🖐其实我在这次目标检测任务中还有一个严重的错误是训练的次数太少，每次看到可能出现了过拟合的情况我就停止训练了，这大概只会跑50轮左右，实际上继续跑的话分数不一定会变差，每次就跑50轮总归是太少了。

我最后的方案就是合并了训练集和验证集，并且增加了图像的输入尺寸，效果又相较于我之前的尝试变好了一些，不过依旧没有超过`baseline`里`submission`的分数。在这个时候我开始意识到可能是我训练的轮数太少了，于是我便开始尝试多跑几轮了。但是！可能是因为我学术不精，我遇到了一个大问题，大概过程就是我把目标检测的模型换成了`RT-DETR`，跑完之后发现不能导出。这浪费了打榜赛前最后一天的时间。

> 🖐我认为出现了这种问题的原因在于一点是我当时太急了，换模型的时候没有进行验证可行性的实验；还有一点是我对模型导出的概念不够清楚，我认为的导出模型就是单纯的动态图转静态图，应该是这个地方的不清晰导致了我后面换模型之后导出失败的情况；还有一点就是作为团队赛我没有发挥好团队的整体作用。



### 3.语义分割数据集分析

相较于目标检测任务来说，分割任务的数据集中的数据量较少，而且纯净度比较高。于是便采用了人眼检查的方式来检测是否存在少量的脏数据。

#### 可视化原始图片和对应mask图片分析

```python
import matplotlib.pyplot as plt
import numpy as np
import os
import cv2

root_img_path = r"C:\Users\20461\PycharmProjects\pythonProject\images\val"
root_png_path = r"C:\Users\20461\PycharmProjects\pythonProject\annotations\val"

img_list = os.listdir(root_img_path)
png_list = os.listdir(root_png_path)
for num in range(len(img_list)):
    imgfile = root_img_path + '\\' + img_list[num]
    pngfile = root_png_path + '\\' + png_list[num]

    img = cv2.imread(imgfile, 1)
    mask = cv2.imread(pngfile, 0)

    contours, _ = cv2.findContours(mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)
    cv2.drawContours(img, contours, -1, (0, 0, 255), 1)

    img = img[:, :, ::-1]
    img[..., 2] = np.where(mask == 1, 255, img[..., 2])

    plt.title(img_list[num])
    plt.imshow(img)
    plt.show()
```

最终在所有图像数据中只发现了三张脏数据：

<img src="https://raw.githubusercontent.com/sixteeeenTang/img-storage/main/QQ%E5%9B%BE%E7%89%8720230730224847.jpg" alt="脏数据1" style="zoom:50%;" />

<img src="https://raw.githubusercontent.com/sixteeeenTang/img-storage/main/QQ%E5%9B%BE%E7%89%8720230730224844.jpg" alt="脏数据2" style="zoom:50%;" />

<img src="https://raw.githubusercontent.com/sixteeeenTang/img-storage/main/QQ%E5%9B%BE%E7%89%8720230730224840.jpg" alt="脏数据3" style="zoom:50%;" />

### 4.语义分割数据集处理

我认为脏数据数量很少所以采取了十分简单粗暴的方式来处理脏数据，就是在训练时直接把这三个数据给删掉了。没有进行额外的数据增强，因为本次分割任务的数据集就已经很干净了，我担心引入噪声反而会降低模型的精度。

> 🖐其实可以自己标一下的，不过我图省事直接给删了



### 5.小结

在本次线上打榜赛中我负责对数据集的处理，对目标检测的数据集进行了很多尝试的同时也引发了我很多的思考，我也从中学习到了很多知识😆虽然从目标检测任务的得分来看并不好，不过我确实学到不少东西；而对于分割任务的数据集来说，我花了相较于目标检测数据集更少的时间，并且取得了更好的效果，这让我觉得有些幸运🤣，不过必须意识到这种偶然幸运只是一种巧合，如果想要收获更多知识取得更好的成绩必须要脚踏实地去钻研和学习。

我认为我在本科阶段我目前能参与的比赛是有限的，在我当下本科二年级阶段参与比赛的目的不在于拿奖，而是提升自己。奖项只是我在提升道路上的证明。如果只是为了拿奖而参与比赛是肤浅的🙁，短期来看能填充和丰富自己的简历，实际上只是埋下一个个祸根的种子，最终大概率会坑自己一把。



## 🎐3.针对目标检测任务的训练

> [第十七届全国大学生智能汽车竞赛：智慧交通组创意赛线上资格赛-冠军方案 - 飞桨AI Studio (baidu.com)](https://aistudio.baidu.com/aistudio/projectdetail/4217664)
>
> [PaddlePaddle/PaddleDetection: Object Detection toolkit based on PaddlePaddle. It supports object detection, instance segmentation, multiple object tracking and real-time multi-person keypoint detection. (github.com)](https://github.com/PaddlePaddle/PaddleDetection)
>
> [目标检测 1 ： 目标检测中的Anchor详解 - Brook_icv - 博客园 (cnblogs.com)](https://www.cnblogs.com/wangguchangqing/p/12012508.html)
>
> [深度学习调优指南中文版 - 深度学习调优指南中文版 (gitbook.io)](https://sourcecode.gitbook.io/ai/#shen-du-xue-xi-tiao-you-zhi-nan-zhong-wen-ban)

实际上这部分任务在本次打榜赛中并不是我主要负责的工作，不过我还是负责了一下。🫤



### 1.配置文件

在本次比赛中虽然官方给出了`baseline`，但是也并不是顺着`baseline`就能一路运行顺畅通关的，需要对本次检测任务来配置文件。

我们需要新建数据集配置文件并且把本次任务的数据集路径和格式正确写进文件中。本次任务中只涉及训练集和验证集，不涉及测试集所以不需要配置测试集。

紧接着便是检测任务模型的配置文件，在检测任务模型的配置文件中，我们本次打榜赛主要修改的内容有：epoch、base_lr、sample_transforms、batch_size

```python
TrainReader:
  sample_transforms:
    - Decode: {}  # 从图像文件或内存buffer中加载图像,格式为RGB格式
    - RandomDistort: {}   # 随机扰动图片亮度、对比度、饱和度和色相
    - RandomExpand: {fill_value: [123.675, 116.28, 103.53]} # 将原始图片放入用像素均值填充的扩张图中，对此图进行裁剪、缩放和翻转
    - RandomCrop: {}  # 原理同CropImage，以随机比例与IoU阈值进行处理
    - RandomFlip: {}  # 随机水平翻转图像
    # - Mixup: {alpha: 1.5, beta: 1.5}  # Mixup数据增强，按比例叠加两张图像
  batch_transforms:
    - BatchRandomResize: {target_size: [320, 352, 384, 416, 448, 480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800, 832, 864, 896, 928, 960], random_size: True, random_interp: True, keep_ratio: False}
    - NormalizeImage: {mean: [0., 0., 0.], std: [1., 1., 1.], norm_type: none}
    - Permute: {}
    - PadGT: {}
  batch_size: 8
  shuffle: true
  drop_last: true
  use_shared_memory: true
  collate_batch: true
  # mixup_epoch使用mixup的轮数，即在epoch < mixup_epoch时一直使用mixup。默认值为-1，表示不使用Mixup
  # mixup_epoch: 100
```

在本次比赛中我们主要使用的模型是`ppyoloe`系列的`l`模型，`baseline`中就是使用的此模型，模型精度和大小（加上分割模型不超过400M）都很符合本次比赛的要求。由于水平有限我们没有修改模型的`backbone`、`检测头`等内容。

> 🖐在模型训练时如果发现显存没有吃满可以调大batchsize以更完全发挥机器的性能，不过需要注意的是batchsize与一些超参数的交互比较强，比如：优化器超参数（学习率、动量）、正则化超参数。所以在修改batchsize时要注意与其交互强的参数的配置。
>
> 🖐一般都是把batchsize调到最大的，所以一般根据batchsize最大的情况调整超参数。
>
> 🖐调的最多的超参数我感觉是学习率

### 2.熟悉PaddlePaddle框架

由于是初次在PaddlePaddle框架下进行项目，花了不少时间去了解和学习PaddlePaddle框架，不过目前也是浅尝辄止，没有很深入的了解，停留在能基础使用的阶段，还需要进阶学习。

### 3.模型训练

由于`ppyoloe_x`模型太大，搭配我们的分割大模型会超过400M，所以就放弃了这个模型。仍然用的是`ppyoloe_l`模型。

```python
%cd ~
%cd PaddleDetection
!python tools/train.py -c configs/ppyoloe/ppyoloe_plus_crn_l_80e_coco.yml \
    --eval \
    --use_vdl=true \
    --vdl_log_dir=vdl_dir/scalar \
    -r output/ppyoloe_plus_crn_l_80e_coco/19
```

这里相较于`baseline`有一些变动，加了一些可选的命令参数：

- `-c`	配置文件的路径
- `--eval`	边训练边验证
- `--use_vdl`	可视化训练时`loss`、`map`等变量变化
- `--vdl_log_dir`	保存可视化文件路径（可以直接在`BML CodeLab`环境中打开）
- `-r`	断点恢复训练

### 4.小结

我们本次目标检测任务可以说十分失败，因为我们最终的目标检测任务分数都是在`baseline`的`submission`中的给出模型的基础上，调整输出阈值来提分的😑。这基本上没有技术含量，纯靠猜，一想到这里我就十分不爽😩



## 🎐4.针对语义分割任务的训练

我本以为这次比赛决定成绩的会是检测任务，但是没想到实际上是分割任务。🥲

不清楚官方的检测任务测试集里都是些啥，但是大家的`f1-score`都很低，而分割任务的成绩就成了非常重要的提升点。

语义分割是我在本次打榜赛中才开始接触的，所以我对语义分割的底层实现其实是并不是很熟悉的，不过我在应用的时候还是有种熟悉的感觉😀

我们团队本次比赛最终能取得这个成绩原因就在于分割任务做得还不错😁

### 1.配置文件

与检测任务一样，需要我们来根据本次任务来配置文件。

然后是配置模型的配置文件，让我比较疑惑的是，为什么`baseline`里给出的`loss`的`type`会定义5次。学习率调整策略用的是Poly策略，并不是余弦周期调整策略。

Poly策略在训练次数增长时学习率的调整趋势

![Poly策略](https://raw.githubusercontent.com/sixteeeenTang/img-storage/main/20210304174515787.png)

### 2.模型选择

我们首先是选择的一些小模型来尝试，比如：`pp_liteseg`、`pp_mobileseg`、`bisenet`，但是表现最好的`pp_mobileseg`分数也没有超过0.49。

随后在用多线程解决了FPS过低的问题之后，我们便开始受龚思宇学长的启发，使用大模型，比如：`deeplabv3p`、`ocrnet`，表现就比小模型要好一些，分数轻松就过了0.49，但是也就在0.50左右徘徊。于是我们便把训练集和验证集进行了合并，去除了脏数据，同时不断调整学习率，并增大训练轮数，最终到了0.51556的分数（`deeplabv3p`）。

### 3.模型训练

```python
# deeplabv3p
%cd ~
%cd PaddleSeg
!python tools/train.py --config configs/deeplabv3p/deeplabv3p_resnet50_os8_voc12aug_512x512_40k.yml \
                 --do_eval \
                 --save_interval 100 \
                 --save_dir output/deeplabv3p_resnet50_os8_voc12aug_512x512_40k_lr0.15
```

### 4.小结

本次语义分割任务我挺满意的😆

不过提升空间应该也还是有的，我看武汉理工的几个队伍的分割任务分数能达到0.54+，不清楚怎么做到的，或许他们加了数据集？（我并没有在网上找到除了本次比赛之外的工业仪表分割数据集）



## 🎐5.模型导出

> [导出模型-PaddlePaddle深度学习平台](https://www.paddlepaddle.org.cn/inference/master/guides/export_model/index_export_model.html)

我对这部分的理解并不深入，我认为模型导出的过程就是动态图模型转换为静态图模型的过程。

目标检测任务的模型导出：

```python
# ppyoloe_l
%cd ~
%cd PaddleDetection
!python tools/export_model.py -c configs/ppyoloe/ppyoloe_plus_crn_l_80e_coco.yml \
                    -o weights=output/ppyoloe_plus_crn_l_80e_coco/best_model.pdparams \
                    TestReader.fuse_normalize=true
```

`RT-DETR`模型在导出时会报错，不清楚是我的问题还是飞桨的问题🤨



语义分割任务的模型导出：

```python
# deeplabv3p
%cd ~
%cd PaddleSeg
!python tools/export.py --config configs/deeplabv3p/deeplabv3p_resnet50_os8_voc12aug_512x512_40k.yml \
                  --model_path output/deeplabv3p_resnet50_os8_voc12aug_512x512_40k_lr0.15/iter_15000/model.pdparams \
                  --save_dir output/deeplabv3p_lr0.15_final
```



## 🎐6.代码提交

> [第十七届全国大学生智能汽车竞赛：智慧交通组创意赛线上资格赛-冠军方案 - 飞桨AI Studio (baidu.com)](https://aistudio.baidu.com/aistudio/projectdetail/4217664)

本部分主要对`det_predict.py`进行了修改，先后受龚思宇学长的帮助有了多线程版本和多进程版本，解决了FPS低于20会导致分数为0的情况。感谢龚思宇学长😍

预测框的输出阈值在这里调整。（在最后几天我们由于时间有限、算力有限，所以把大部分成本投入了看上去更容易提分的分割任务中，导致我们对目标检测任务能做的就有限了）但是我很不甘心🫥，下次如果再有机会我一定不会让这种情况再发生！



# ✨总结

1. 从学习收获的角度来看。我在本次打榜赛中学到了很多有用的知识，不光是一些基础理论知识，还有具体的实践应用结合，我是很满意的。😄

2. 从团队协作的角度来看。我们团队有四个人，在打榜赛阶段由三人承担算法工作（其中我主要负责数据集的分析和处理、王宇航主要负责目标检测任务、何罗坤主要负责语义分割任务）。由于我作为队长过于对自身能力的自信，把大部分事情都揽到自己的身上，所以没有分配好任务，导致团队协作出现了一些混乱。在以后的团队合作任务中我应该更重视队员之间的合作，而不是队员之间分散工作。😔

   以后如果还有团队线上打榜赛的话，应该采用更便捷高效的合作方式（比如：使用在线表格来记录大家的奇思妙想和有趣尝试）😎

3. 从打榜赛的结果来看。作为我第一次在深度学习领域的比赛实践，我个人认为还不错，不过也还有很大的提升空间的。😝

4. 针对在本次目标检测任务中我主要犯的错误（训练次数太少、过度依赖验证集的评估结果），以后要尽量避免犯同样的错误。😢

5. 遭遇了挫折的时候要自信，不能过于灰心，在本次打榜赛中我就因为自己的想法被测试结果狠狠地否定而灰心了很长一段时间。以后的路还长，遇到的挫折和困难还会有的，不能被击倒了。🥹

6. ==最后特别鸣谢：龚思宇学长😍😍😍==



🥳作者：sixteentang
