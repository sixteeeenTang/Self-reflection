------

[TOC]



------

# 🎆“中国软件杯”大学生软件设计大赛——飞桨小汪赛道

<details>
<summary>线下赛规则</summary>
看不到我 看不到我 O(∩_∩)O
</details>


# ✨区域赛结果

拿了97分（满分100分），全国三等奖   https://www.cnsoftbei.com/plus/view.php?aid=873

![获奖情况](https://raw.githubusercontent.com/sixteeeenTang/img-storage/main/Quicker_20230806_174300.png)

相较于我最初的预想来说应该算有些失败，但是已经算尽力挽回的程度了。

对于这个结果，我不认为是我个人技术能力不足的问题。

> 接下来我要怒砸钢琴了！😤

# ✨规则

[线下赛规则](https://github.com/sixteeeenTang/img-storage/blob/main/%E3%80%90%E8%A7%84%E5%88%99%E8%AF%B4%E6%98%8E%E3%80%912023%E4%B8%AD%E5%9B%BD%E8%BD%AF%E4%BB%B6%E6%9D%AF%E9%A3%9E%E6%A1%A8%E5%B0%8F%E6%B1%AA%E7%BA%BF%E4%B8%8B%E8%B5%9B%E8%A7%84%E5%88%99.pdf)

# ✨复盘大致的过程

## 🎐任务分析

> 不同的人和机器狗的命运是不同的，悲😭
>
> 我们队的机器狗的左腿电机有一些问题，导致有时候不能正常行走和转弯（瘸了😭），而且15号板卡通过源码编译的OpenCV没有aruco库，这导致了我们的跨越台阶任务、避障任务和终点定位任务都无法通过识别aruco码来实现，能想到的方法都试了一遍，不过还是没能解决我的问题，发现全都不行之后决定重装OpenCV，但是结果就是把环境给搞坏了，还送回去修了5天（这5天还是在最关键的5天）😭
>
> 最后能完赛还是用了学校里另外一个队伍的机器狗😭
>
> 当我看到别的队伍的狗健壮的身姿，我总会忍不住想到我们队伍的瘸狗，我的心中只是无限的感慨，人和人的时运也是有差别的😭

首先是任务的确定

区域赛的主要任务我认为是五个：

1. 巡线任务

   让机器狗沿地图中的黑色引导线行进。

2. 目标检测任务

   使用机器狗身上的相机捕获图像，并进行目标检测任务，同时对于检测的结果做出相应的反应，比如：检测到视野中有火点的话需要使头部灯带亮出红灯，检测到视野中有工业仪表的话需要让机器狗做出抬头动作。

3. 跨越台阶任务

   地图上会放置一个黑色的大台阶，需要让机器狗跨越这个台阶。

4. 避障任务

   地图上会放置一个绿色的障碍物，需要让机器狗避开这个障碍物。

5. 终点定位任务

   机器狗在完成了目标检测任务、跨越台阶任务、避障任务之后需要回归到一个指定的终点。

其中**巡线任务、目标检测任务**是最重要的两个任务，这直接关乎到整个比赛的完成度

> 由于官方推荐使用的aruco码不能用，我最终选择用别的方法来处理跨越台阶、避障、终点定位的问题🤕
>
> 跨越台阶和避障都通过识别对应任务颜色和图像面积颜色的比例来完成，终点定位问题通过计时器来完成。结果就是跨越台阶和避障问题都能很好完成，早知道这样我就不动那个aruco库了，气死我了！😵
>
> 终点定位问题其实也可以用颜色识别来完成的，但是我当时已经处于一个极度悲伤和消极的状态，就没写。😵

我在不同的板卡运行各自的程序，通过udp进行通信，进而完成一系列的任务

主要是15号板卡、14号板卡、13号板卡

- 13号板卡 (Nano1)

  相机发送图像的程序`example_putimagetrans_1`

  灯带接收程序`led`

- 14号板卡 (Nano2)

  目标检测的程序`body_left`和`body_right`

- 15号板卡 (Nano3)

  总控程序`inspectionDog_Mulitprocess.py`

## 🎐15号板卡

所有任务的完成基本是放在15号板卡（主控nano）的`inspectionDog_Mulitprocess.py`文件中，其中设置了四个进程，用来处理**巡线, 接收信息, 决策主控, 检测绿色障碍物**这四个问题（接受信息是用来接收来自14号板卡身体两侧相机目标检测结果的；检测绿色障碍物由于用到了头部的前方摄像头，与巡线的摄像头不同，所以单独设置了一个进程来处理）

使用了队列来实现不同进程之间的信息共享

### 巡线进程函数

主要思路是调用`followBlackLine`函数实现机器狗巡线状态的判断，并且将巡线的状态put到队列中

主要有五个状态，分别是`FollowState`, `TurnState`, `SearchState`, `StepStairsState`, `ToAvoidState`

用来表示：直走状态，转弯状态，回归终点状态，跨越台阶状态，避障状态

```python
# process 0 
# 巡线进程 
def path_follow(self, quene):
    # ----------------------初始化类-------------------------------
    cap = Stereo_Camera(1)  # 下巴相机
    cap.camera_init()
    self.last_target_point = 0
    # ----------------------循环进程-------------------------------
    while True:
        start = time.time()
        res, state_list = self.followBlackLine(cap, color="chin_black_path")
        target_point = state_list[0]
        if target_point == None:
        state_list[0] = self.last_target_point
        self.last_target_point = target_point

        quene.put([0, res, state_list]) # 发送消息
        print("Process0 FPS:", 1/(time.time()-start), "/s")
```



### udp接收信息进程函数

这个进程用udp接收来自14号板卡目标检测任务的结果，并将结果put到队列中

主要调用了`receive_udp_data`函数来实现接收目标检测任务的结果

```python
# process 1
# udp接收信息进程 
def receive_pack(self, quene):
    # ----------------------初始化变量-------------------------------
    port = [8900, 8901]   # 分别监听15号板卡8900端口、15号板卡8901端口
    # ----------------------循环进程-------------------------------
    while True:
        start = time.time()
        pack = [0, 1]
        pack = [receive_udp_data(i) for i in port]
        # print('mode',pack[0].mode,pack[1].mode)
        # 判断是否属于 fire_mode(pack[0]接受为1)、meter_mode(pack[1]接受为2)
        print('pack',pack[0].mode,pack[1].mode,type(pack[0].mode[0]))

        mode_list = [False, False]

        mode_list[0] = True if int(pack[0].mode[0]) == 1 else False
        mode_list[1] = True if int(pack[1].mode[0]) == 2 else False

        print('mode_list',mode_list)
        quene.put([1, mode_list])    # 第一个元素1代表着该进程的id，用于share_list共享数据时进行识别
        print("Process1 FPS:", 1/(time.time()-start), "/s")
```



### 主控进程函数

重中之重，非常重要。

主要通过get队列中的消息，把消息传入`policyDecision`函数来做出决策，判断当前应该做出什么决策；
然后调用将决策的结果传入`motionControl`函数来进行机器狗的运动控制

```python
# process 2
# 主控制进程 √
def main_control(self, quene):
    # ----------------------初始化类-------------------------------
    unitree_robot = Unitree_Robot()
    RobotStartStart = False
    self.last_motion_mode = 0
    self.last_target_point = 0
    self.last_state_list = [False for i in range(5)]
    self.last_mode_list = [False for i in range(2)]
    Start_Time = time.time()
    # ----------------------循环进程-------------------------------
    while True:        
        start = time.time()
        # 获取队列消息
        data = quene.get()
        if data[0] == 0 or data[0] == 3:  # 如果是进程0或者进程3发送来的数据，则有三个数据，分别是进程id、图像、共享列表
            process_id, frame, share_list = data
            # print([process_id, frame, share_list])
        else:   # 如果是进程1发送来的数据，则只有两个数据，分别是进程id、共享列表
            process_id, share_list = data
            # print([process_id, share_list]) # 来自进程1，打印 mode_list
        # 等待进程0启动后再开始进行运动控制
        if not RobotStartStart:
            if process_id == 0:
                RobotStartStart = True
            continue
        
        # 逻辑决策
        motion_mode, target_point, state_list = self.policyDecision(process_id, share_list)

        LastTime = 138
        print(time.time() - Start_Time)
        if time.time()-Start_Time >= LastTime:
            
            state_list = [False, False, True, False, False]
        # 运动控制
        if RobotStartStart:
            self.motionControl(unitree_robot, motion_mode, target_point, state_list)
        
        # 保存视频
        if process_id == 0:
            self.saveVedio(process_id, frame)
    # 结束进程
    self.processEnd()
```



### 障碍物识别进程函数

主要是使用头部前方摄像头，调用`GreenObstacleArea`函数来判断是否遇到绿色障碍物

该进程函数的原理和巡线进程函数类似（巡线进程是用的下巴相机，障碍物识别进程用的是前方相机）

```python
# process 3
# 障碍物识别进程 √
def green_obstacle(self, quene):
    # ----------------------初始化类-------------------------------
    cap = Stereo_Camera(0)  # 前方摄像头
    cap.camera_init()
    # ----------------------循环进程-------------------------------
    while True:
        # 识别前方绿色像素占图像面积
        start = time.time()
        res, state_list = self.GreenObstacleArea(cap, color='forward_green_obstacle')
        
        # 只有超过阈值识别到绿色之后才发送，不然可能会造成进程0的信息被进程3覆盖
        if state_list[5] == True:
            quene.put([3, res, state_list]) # 发送消息
            print("Process3 FPS:", 1/(time.time()-start), "/s")

```



### 具体函数的详细内容

#### 1.followBlackLine函数

利用了OpenCV对图像进行处理和分析。

首先是**对图像色彩空间的转换**，方便后续的处理。同时**设置对黑色引导线识别的上下限阈值**，方便提取黑色引导线。

```python
color_dist = {
              'forward_green_obstacle': {'Lower': np.array([60, 130, 80]), 'Upper': np.array([150, 255, 255])},
              'chin_black_path': {'Lower': np.array([0, 0, 0]), 'Upper': np.array([180, 255, 80])},  
              }
```

然后就是划定感兴趣图像区域，并且在此区域内**对图像中的黑色引导线进行提取**

需要注意的是，这个算法先对于图像中的**前40行**像素进行识别，若是有黑色引导线，则认为当先的引导线是直线，需要直走；然后，若是前一种情况没有识别到黑色引导线，则对图像中的**40至300行**像素进行识别，若是有黑色引导线，则认为当前的引导线是有折角的，需要转弯。返回值为机器狗运动控制的参数和标志位，方便在运动控制函数中接受当前需要更改的运动状态

直走和转弯的情况如图：

![直走](https://raw.githubusercontent.com/sixteeeenTang/img-storage/main/Quicker_20230731_152551.png)

![转弯](https://raw.githubusercontent.com/sixteeeenTang/img-storage/main/Quicker_20230731_152622.png)



#### 2.GreenObstacleArea函数

整体结构与`followBlackLine`函数类似，但是直接使用了整张图像作为感兴趣区域，在其中计算绿色像色占整个图像面积的比例，超过我设置的阈值则认为遇到了绿色障碍物，于是开始进行避障操作



#### 3.receive_udp_data函数

用socket库来处理来自14号板卡发送的消息，需要注意的是在14号板卡发送来的pack是一个结构体PACK，所以还用到了struct库，并且需要指定接收的数据长度！



#### 4.policyDecision函数

由于区域赛的地图是固定的，任务难度小，所以决策树比较简单

```python
@ 决策树:
    (0)巡线模式:
        默认模式，13卡下巴检测到黑线；

    (1)火焰模式:
        模式入口状态: 14卡右侧相机检测到火焰
        模式功能: 静止站立并且灯带发出亮光
        
    (2)仪表模式:
        模式入口状态: 14卡左侧相机检测到仪表
        模式功能: 抬头
```

解析不同进程共享队列的消息，通过决策树来判断当前应该变更的状态

不过需要额外注意的一个点是目标检测任务的**误检问题**，由于目标检测任务在14号板卡，所以15号板卡只负责接收来自14号板卡的结果，我设置了一些标志变量，使得只会进行一次目标检测任务对应的动作，这样可以避免后续巡线过程中可能遇到的误检问题而导致的错误动作



#### 5.motionControl函数

此函数接收`policyDecision`函数的结果并作为运动控制的判断

需要注意的是，对不同的机器狗，高层封装的运动控制代码里的运动控制参数需要具体调整

例如：

```python
if FollowState:
    state = unitree_robot.robot_walking(gaitType = 1, forwardSpeed = 0.15, sidewaySpeed = 0, 
                                    rotateSpeed = target_point*1.5, speedLevel = 0, bodyHeight = -0.2)
```

经过我的测试，不同的机器狗的话，想要达到一致的运动控制效果需要再具体调整这些参数（这说明了矛盾的特殊性😂）



## 🎐14号板卡

14号板卡上有身体两侧的相机，用来处理目标检测的任务，使用的框架是paddle

使用`body_left`和`body_right`两个程序分别处理身体左侧的目标检测任务和身体右侧的目标检测任务（两个程序基本一样，具体差别在使用的相机不同以及通信的地址不同）

预测器的初始化很重要，这直接关乎到能否正确开始目标检测

其次就是对结果的处理，由于我选取的模型是小模型，所以出现了一定程度的误检问题，可以通过设置大阈值来让输出结果更精准（不过这个也和训练模型时的数据集有密切关系），最终我选取的阈值均为0.8+（这么高是因为目标检测任务很简单，只会出现两张图像，一张火点， 一张仪表，并且图像已经给出了，我训练所用的数据集就是根据这两张图片采集的🤣）

最后是发送消息到15号板卡和13号板卡，需要注意IP地址和端口号，要使用没被占用的端口号



## 🎐13号板卡

13号板卡上有下巴相机和前方相机，分别用于巡线和避障任务

`example_putimagetrans_1`程序可以同时打开两个相机并发送到15号板卡

但是13号板卡不负责处理图像，只负责传输图像到15号板卡，具体对图像的处理在15号板卡进行（这点和14号板卡上的目标检测任务不同）

13号板卡上还有灯带，在火点检测的时候需要亮红灯

`led`程序可以收14号板卡发送的目标检测结果来进行亮红灯操作

# ✨总结

其实还有很多细节可以写，但是我不想写了，有些累（精神上的疲惫）。基本的整体框架就是这样了。

这个机器狗的比赛我花了不少时间和精力，虽然止步于区域赛了，但是我觉得还是对我有很多帮助的。

若是作为一个团队的领导者，必须要果断，该做出决断的时候一定要敢做，不然团队成员做啥事就全看成员自己。做人也是这样，我性格或许太过于温和了，不能一直都这么温和，不然我也太好欺负了吧！😥

感觉作为团队的领导者进行团队管理还是很有难度的，但是感觉团队沟通的成本有点高。

当我一个人能完成基本90%的任务的时候就干脆一个人搞好了。🥲



结束了这个比赛和同期进行的计算机设计大赛，我的感觉就是，团队作战大失败！因为付出的努力和获得的收获完全不是一个层次，付出的努力是国奖的程度，但是只有省奖的收获。这两个比赛我均是作为领导者，当个合格的领导者好难啊🥲，负责技术方面的工作就已经很累了，还要负责团队的管理协调等诸多事情，这让我分身乏术。或许我该找几个技术力好一些的人来当队友，这样可以分担我的一部分工作，让我可以有精力来管理团队🤔

虽然结果已经是这个样子了，但是我还是感谢和我一起努力过的同伴们。😆

失败乃是成功之母，下次一定成功！😊



🥳作者：sixteentang
